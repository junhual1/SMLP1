{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "from keras import layers\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout, Layer\n",
    "from tensorflow.keras.layers import Embedding, Input, GlobalAveragePooling1D, Dense, Concatenate\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import pickle\n",
    "\n",
    "NUM_TOKEN = 5000\n",
    "MAX_PRO_LEN = 64\n",
    "MAX_TXT_LEN = 256\n",
    "NO_EPO = 60\n",
    "NO_BAT = 128\n",
    "CLS = 5001\n",
    "SEP = 5002\n",
    "PAD_ID = 0\n",
    "\n",
    "MACHINE_1_P = \"./data/set1_machine.json\"\n",
    "HUMAN_1_P = \"./data/set1_human.json\"\n",
    "MACHINE_2_P = \"./data/set2_machine.json\"\n",
    "HUMAN_2_P = \"./data/set2_human.json\"\n",
    "TEST_P = \"./data/test.json\"\n",
    "RANDOM_SEED = 42\n",
    "MACHINE_IND = 0\n",
    "HUMAN_IND = 1\n",
    "TEST_FRA = 0.2\n",
    "\n",
    "class DomainData:\n",
    "    \"\"\"\n",
    "    train_test_split, pad_sequence, class_weight\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def t_t_spli(self, test_size, random_state):\n",
    "        self.random_state = random_state\n",
    "        self.train_x, self.test_x, self.train_y, self.test_y = train_test_split(self.x, self.y, test_size=test_size, stratify = self.y, random_state = random_state)\n",
    "        self.train_x = self.train_x.reset_index(drop=True)\n",
    "        self.train_y = self.train_y.reset_index(drop=True)\n",
    "        self.test_x = self.test_x.reset_index(drop=True)\n",
    "        self.test_y = self.test_y.reset_index(drop=True)\n",
    "        \n",
    "    def add_sep(self):\n",
    "        self.x[\"prompt\"] = self.x.apply(lambda x: [i+1 for i in x[\"prompt\"]] , axis = 1)\n",
    "        self.x[\"prompt\"] = self.x.apply(lambda x: [CLS] + x[\"prompt\"] , axis = 1)\n",
    "        self.x[\"prompt\"] = self.x.apply(lambda x: x[\"prompt\"] + [SEP] if len(x[\"prompt\"])<MAX_PRO_LEN else x[\"prompt\"][:MAX_PRO_LEN-1] + [SEP], axis = 1)\n",
    "\n",
    "        self.x[\"txt\"] = self.x.apply(lambda x: [i+1 for i in x[\"txt\"]] , axis = 1)\n",
    "        self.x[\"txt\"] = self.x.apply(lambda x: [CLS] + x[\"txt\"] , axis = 1)\n",
    "        self.x[\"txt\"] = self.x.apply(lambda x: x[\"txt\"] + [SEP] if len(x[\"prompt\"])<MAX_TXT_LEN else x[\"txt\"][:MAX_TXT_LEN-1] + [SEP], axis = 1)\n",
    "        \n",
    "    \n",
    "    def add_padding(self, padding, prompt_len, txt_len):\n",
    "        self.train_prompt = self.train_x[\"prompt\"]\n",
    "        self.train_txt = self.train_x[\"txt\"]\n",
    "        self.train_label = self.train_y.to_numpy()\n",
    "        self.test_prompt = self.test_x[\"prompt\"]\n",
    "        self.test_txt = self.test_x[\"txt\"]\n",
    "        self.test_label = self.test_y.to_numpy()\n",
    "        unique_classes = np.unique(self.train_label)\n",
    "        class_weights = class_weight.compute_class_weight(\"balanced\", classes=unique_classes, y=self.train_y)\n",
    "        self.class_weights = dict(zip(unique_classes, class_weights))\n",
    "        \n",
    "        self.prompt_len = prompt_len\n",
    "        self.txt_len = txt_len\n",
    "        \n",
    "        self.train_prompt = pad_sequences(self.train_prompt, padding=padding, maxlen=prompt_len, value=PAD_ID)\n",
    "        self.train_txt = pad_sequences(self.train_txt, padding=padding, maxlen=txt_len, value=PAD_ID)\n",
    "        self.test_prompt = pad_sequences(self.test_prompt, padding=padding, maxlen=prompt_len, value=PAD_ID)\n",
    "        self.test_txt = pad_sequences(self.test_txt, padding=padding, maxlen=txt_len, value=PAD_ID)\n",
    "        \n",
    "        \n",
    "    def down_sampling(self):\n",
    "        mac_ind = self.train_y[self.train_y == MACHINE_IND].index.to_list()\n",
    "        hum_ind = self.train_y[self.train_y == HUMAN_IND].index.to_list()\n",
    "        lower = min(len(mac_ind), len(hum_ind))\n",
    "        sel_lit = mac_ind[:lower] + hum_ind[:lower]\n",
    "        self.train_x = self.train_x.iloc[sel_lit]\n",
    "        self.train_y = self.train_y.iloc[sel_lit]\n",
    "        random.shuffle(sel_lit)\n",
    "\n",
    "    def over_sampling(self, upper_fra):\n",
    "        mac_ind = self.train_y[self.train_y == MACHINE_IND].index.to_list()\n",
    "        hum_ind = self.train_y[self.train_y == HUMAN_IND].index.to_list()\n",
    "        lower = min(len(mac_ind), len(hum_ind))\n",
    "        if lower == len(mac_ind):\n",
    "            upper = int(lower*upper_fra) if lower*upper_fra < len(hum_ind) else len(hum_ind)\n",
    "            major = hum_ind[:upper]\n",
    "            minor = mac_ind[:lower]\n",
    "    \n",
    "        else:\n",
    "            upper = int(lower*upper_fra) if lower*upper_fra < len(mac_ind) else len(mac_ind)\n",
    "            major = mac_ind[:upper]\n",
    "            minor = hum_ind[:lower]\n",
    "        \n",
    "        add_n = upper - lower\n",
    "        oversampled = []\n",
    "        while(len(oversampled) < add_n):\n",
    "            oversampled.append(random.choice(mac_ind))\n",
    "        sel_lit = major + minor + oversampled\n",
    "        random.shuffle(sel_lit)\n",
    "        \n",
    "        self.train_x = self.train_x.iloc[sel_lit]\n",
    "        self.train_y = self.train_y.iloc[sel_lit]\n",
    "    \n",
    "    def test_down(self, frac = 1):\n",
    "        mac_ind = self.test_y[self.test_y == MACHINE_IND].index.to_list()\n",
    "        hum_ind = self.test_y[self.test_y == HUMAN_IND].index.to_list()\n",
    "        lower = min(len(mac_ind), len(hum_ind))\n",
    "        if frac > 1:\n",
    "            sel_lit = mac_ind[:lower] + hum_ind[:int(lower/frac)]\n",
    "        else:\n",
    "            sel_lit = mac_ind[:int(lower*frac)] + hum_ind[:lower]\n",
    "        self.test_x = self.test_x.iloc[sel_lit]\n",
    "        self.test_y = self.test_y.iloc[sel_lit]\n",
    "        random.shuffle(sel_lit)\n",
    "    \n",
    "    def word2vec(self, vector_size = 100, min_count = 1, file_name = None, model = None):\n",
    "        if model:\n",
    "            self.w2v_model = model\n",
    "        elif file_name:\n",
    "            self.w2v_model = Word2Vec.load(file_name)\n",
    "        else:\n",
    "            w2v_prompt = []\n",
    "            for i in self.train_prompt:\n",
    "                w2v_prompt.append(i[np.nonzero(i)])\n",
    "\n",
    "            w2v_txt = []\n",
    "            for i in self.train_txt:\n",
    "                w2v_txt.append(i[np.nonzero(i)])\n",
    "\n",
    "            w2v_train = [list(w2v_prompt[i]) + list(w2v_txt[i]) for i in range(len(self.train_prompt))]\n",
    "            print(\"text merged\")\n",
    "            sentences = [list(map(str, doc)) for doc in w2v_train]\n",
    "            sentences.append(range(NUM_TOKEN))\n",
    "            self.w2v_model = Word2Vec(sentences, vector_size=100, min_count = 1)\n",
    "        self.train_prompt = np.array([np.mean([self.w2v_model.wv[i] for i in j], axis=0) for j in self.train_prompt])\n",
    "        self.train_txt = np.array([np.mean([self.w2v_model.wv[i] for i in j], axis=0) for j in self.train_txt])\n",
    "        self.test_prompt = np.array([np.mean([self.w2v_model.wv[i] for i in j], axis=0) for j in self.test_prompt])\n",
    "        self.test_txt = np.array([np.mean([self.w2v_model.wv[i] for i in j], axis=0) for j in self.test_txt])\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    # Calculate precision and recall\n",
    "    tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)))\n",
    "    fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)))\n",
    "    fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)))\n",
    "    precision = tp / (tp + fp + backend.epsilon())\n",
    "    recall = tp / (tp + fn + backend.epsilon())\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1_score = 2 * precision * recall / (precision + recall + backend.epsilon())\n",
    "    \n",
    "    # Return negative F1 score as the loss (to minimize it)\n",
    "    return -f1_score\n",
    "\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience = 3)\n",
    "random.seed(RANDOM_SEED)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "if len(tf.config.list_physical_devices('GPU')):\n",
    "    tf.config.list_physical_devices('GPU')\n",
    "    print(\"Using GPU\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text merged\n"
     ]
    }
   ],
   "source": [
    "vector_size = 64\n",
    "\n",
    "## _______________ Read data from domain 1 _______________\n",
    "man_1_df = pd.read_json(HUMAN_1_P)\n",
    "man_1_df[\"label\"] = HUMAN_IND\n",
    "mac_1_df = pd.read_json(MACHINE_1_P).drop(\"machine_id\", axis = 1)\n",
    "mac_1_df[\"label\"] = MACHINE_IND\n",
    "domain_1_df = pd.concat([man_1_df, mac_1_df])\n",
    "\n",
    "domain_1 = DomainData(domain_1_df[[\"prompt\", \"txt\"]], domain_1_df[\"label\"])\n",
    "domain_1.t_t_spli(TEST_FRA, RANDOM_SEED)\n",
    "# domain_1.over_sampling(1.6)\n",
    "domain_1.test_down()\n",
    "domain_1.add_padding('post', MAX_PRO_LEN, MAX_TXT_LEN)\n",
    "# domain_1.word2vec(vector_size, 1, \"Word2Vec_1.model\")\n",
    "domain_1.word2vec(vector_size, 1)\n",
    "domain_1.w2v_model.save(\"Word2Vec_1.model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1] [0 0 0 ... 1 1 1]\n",
      "Domain 1 -- F1 score on the test data:  0.8681397006414826\n",
      "confusion matrix: \n",
      " [[606  94]\n",
      " [ 91 609]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "c = 22\n",
    "\n",
    "\n",
    "# Train a logistic regression model on the training data\n",
    "clf = LogisticRegression(max_iter = 1000, C=c, class_weight=domain_1.class_weights)\n",
    "clf.fit(domain_1.train_txt, domain_1.train_label)\n",
    "with open(\"lr_d1_v1.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(domain_1.test_txt)\n",
    "\n",
    "# Calculate the F1 score for the predictions\n",
    "f1 = f1_score(domain_1.test_label, y_pred)\n",
    "\n",
    "print(domain_1.test_label, y_pred)\n",
    "\n",
    "print(\"Domain 1 -- F1 score on the test data: \", f1)\n",
    "print(\"confusion matrix: \\n\", confusion_matrix(domain_1.test_label, y_pred))\n",
    "\n",
    "# 32/29: 100, 1\n",
    "# vs64 c22-> 609/609\n",
    "# vs32 c22-> 605/605\n",
    "# vs80 c22-> 606/609"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text merged\n"
     ]
    }
   ],
   "source": [
    "vector_size = 100\n",
    "\n",
    "## _______________ Read data from domain 2 _______________\n",
    "man_2_df = pd.read_json(HUMAN_2_P)\n",
    "man_2_df[\"label\"] = HUMAN_IND\n",
    "mac_2_df = pd.read_json(MACHINE_2_P).drop(\"machine_id\", axis = 1)\n",
    "mac_2_df[\"label\"] = MACHINE_IND\n",
    "domain_2_df = pd.concat([man_2_df, mac_2_df])\n",
    "\n",
    "domain_2 = DomainData(domain_2_df[[\"prompt\", \"txt\"]], domain_2_df[\"label\"])\n",
    "domain_2.t_t_spli(TEST_FRA, RANDOM_SEED)\n",
    "# domain_2.over_sampling(1.6)\n",
    "domain_2.test_down()\n",
    "domain_2.add_padding('post', MAX_PRO_LEN, MAX_TXT_LEN)\n",
    "# domain_2.word2vec(vector_size, 1, \"Word2Vec_2.model\")\n",
    "domain_2.word2vec(vector_size, 1)\n",
    "# domain_2.w2v_model.save(\"Word2Vec_2.model\")\n",
    "domain_2.w2v_model.save(\"Word2Vec_2.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(domain_2.test_label))\n",
    "print(domain_2.test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1] [1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1]\n",
      "Domain 2 -- F1 score on the test data:  0.7407407407407407\n",
      "confusion matrix: \n",
      " [[ 6 14]\n",
      " [ 0 20]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Train a logistic regression model on the training data\n",
    "clf = LogisticRegression(class_weight=domain_2.class_weights)\n",
    "clf.fit(domain_2.train_txt, domain_2.train_label)\n",
    "with open(\"lr_d2_v1.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "y_pred = clf.predict(domain_2.test_txt)\n",
    "\n",
    "# Calculate the F1 score for the predictions\n",
    "f1 = f1_score(domain_2.test_label, y_pred)\n",
    "\n",
    "print(domain_2.test_label, y_pred)\n",
    "\n",
    "print(\"Domain 2 -- F1 score on the test data: \", f1)\n",
    "print(\"confusion matrix: \\n\", confusion_matrix(domain_2.test_label, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample weight class 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text merged\n"
     ]
    }
   ],
   "source": [
    "over_fra = 1.6\n",
    "weight_fra = 100\n",
    "vector_size = 50\n",
    "\n",
    "## _______________ Read data from domain 1 _______________\n",
    "man_1_df = pd.read_json(HUMAN_1_P)\n",
    "man_1_df[\"label\"] = HUMAN_IND\n",
    "mac_1_df = pd.read_json(MACHINE_1_P).drop(\"machine_id\", axis = 1)\n",
    "mac_1_df[\"label\"] = MACHINE_IND\n",
    "domain_1_df = pd.concat([man_1_df, mac_1_df])\n",
    "\n",
    "domain_1 = DomainData(domain_1_df[[\"prompt\", \"txt\"]], domain_1_df[\"label\"])\n",
    "domain_1.t_t_spli(TEST_FRA, RANDOM_SEED)\n",
    "# domain_1.over_sampling(over_fra)\n",
    "# domain_1.down_sampling()\n",
    "domain_1.add_padding('post', MAX_PRO_LEN, MAX_TXT_LEN)\n",
    "\n",
    "## _______________ Read data from domain 2 _______________\n",
    "man_2_df = pd.read_json(HUMAN_2_P)\n",
    "man_2_df[\"label\"] = HUMAN_IND\n",
    "mac_2_df = pd.read_json(MACHINE_2_P).drop(\"machine_id\", axis = 1)\n",
    "mac_2_df[\"label\"] = MACHINE_IND\n",
    "domain_2_df = pd.concat([man_2_df, mac_2_df])\n",
    "\n",
    "domain_2 = DomainData(domain_2_df[[\"prompt\", \"txt\"]], domain_2_df[\"label\"])\n",
    "domain_2.t_t_spli(TEST_FRA, RANDOM_SEED)\n",
    "# domain_2.over_sampling(over_fra)\n",
    "domain_2.test_down()\n",
    "domain_2.add_padding('post', MAX_PRO_LEN, MAX_TXT_LEN)\n",
    "# domain_2.word2vec(vector_size, 1, \"Word2Vec_2.model\")\n",
    "domain_2.word2vec(vector_size, 1)\n",
    "domain_2.w2v_model.save(\"Word2Vec_2.model\")\n",
    "\n",
    "## _______________ weight data _______________\n",
    "sample_weight_1 = np.ones(len(domain_1.train_label))\n",
    "sample_weight_2 = np.ones(len(domain_2.train_label))\n",
    "sample_weight_2 *= weight_fra\n",
    "sample_weight = np.concatenate([sample_weight_1, sample_weight_2])\n",
    "\n",
    "train_prompt = np.array([np.mean([domain_2.w2v_model.wv[i] for i in j], axis=0) for j in domain_1.train_prompt])\n",
    "train_txt = np.array([np.mean([domain_2.w2v_model.wv[i] for i in j], axis=0) for j in domain_1.train_txt])\n",
    "train_prompt = np.concatenate([train_prompt, domain_2.train_prompt])\n",
    "train_txt = np.concatenate([train_txt, domain_2.train_txt])\n",
    "train_label = np.concatenate([domain_1.train_label, domain_2.train_label])\n",
    "\n",
    "data = list(zip(train_prompt, train_txt, train_label, sample_weight))\n",
    "random.shuffle(data)\n",
    "\n",
    "train_prompt, train_txt, train_label, sample_weight = zip(*data)\n",
    "train_prompt = np.array(train_prompt)\n",
    "train_txt = np.array(train_txt)\n",
    "train_label = np.array(train_label)\n",
    "sample_weight = np.array(sample_weight)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1]\n",
      "Domain 2 -- F1 score on the test data:  0.6666666666666666\n",
      "confusion matrix: \n",
      " [[ 0 20]\n",
      " [ 0 20]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Train a logistic regression model on the training data\n",
    "clf = LogisticRegression(class_weight=domain_2.class_weights)\n",
    "clf.fit(train_txt, train_label, sample_weight = sample_weight)\n",
    "\n",
    "y_pred = clf.predict(domain_2.test_txt)\n",
    "\n",
    "# Calculate the F1 score for the predictions\n",
    "f1 = f1_score(domain_2.test_label, y_pred)\n",
    "\n",
    "print(domain_2.test_label, y_pred)\n",
    "\n",
    "print(\"Domain 2 -- F1 score on the test data: \", f1)\n",
    "print(\"confusion matrix: \\n\", confusion_matrix(domain_2.test_label, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAIN_SPL = 600\n",
    "\n",
    "w2v_model_1 = Word2Vec.load(\"Word2Vec_1.model\")\n",
    "w2v_model_2 = Word2Vec.load(\"Word2Vec_2.model\")\n",
    "test_df = pd.read_json(TEST_P)\n",
    "test_txt = list(pad_sequences(test_df[\"txt\"], padding=\"post\", maxlen=MAX_TXT_LEN))\n",
    "\n",
    "\n",
    "test_txt[:DOMAIN_SPL] = np.array([np.mean([w2v_model_1.wv[i] for i in j], axis=0) for j in test_txt[:DOMAIN_SPL]])\n",
    "test_txt[DOMAIN_SPL:] = np.array([np.mean([w2v_model_2.wv[i] for i in j], axis=0) for j in test_txt[DOMAIN_SPL:]])\n",
    "with open(\"lr_d1_v1.pkl\", \"rb\") as f:\n",
    "    model_1 = pickle.load(f)\n",
    "with open(\"lr_d2_v1.pkl\", \"rb\") as f:\n",
    "    model_2 = pickle.load(f)\n",
    "\n",
    "pred = []\n",
    "pred += model_1.predict(test_txt[:DOMAIN_SPL]).tolist()\n",
    "pred += model_2.predict(test_txt[DOMAIN_SPL:]).tolist()\n",
    "pred = [int(i) for i in np.round(pred).flatten()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred)\n",
    "pred_df.columns = [\"Predicted\"]\n",
    "pred_df.index.names = ['Id']\n",
    "\n",
    "pred_df.to_csv(\"./data/result7.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draft"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
