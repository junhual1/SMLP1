{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48f6fc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55a69ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "def load_dataset(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Convert sequence of integers to string\n",
    "def int_list_to_str(int_list):\n",
    "    return ' '.join(map(str, int_list))\n",
    "\n",
    "# Load data\n",
    "set1_human = load_dataset(\"./data/set1_human.json\")\n",
    "set1_machine = load_dataset(\"./data/set1_machine.json\")\n",
    "set1_machine = set1_machine.drop('machine_id', axis=1)\n",
    "set2_human = load_dataset(\"./data/set2_human.json\")\n",
    "set2_machine = load_dataset(\"./data/set2_machine.json\")\n",
    "set2_machine = set2_machine.drop('machine_id', axis=1)\n",
    "\n",
    "# Label data and combine\n",
    "set1_human[\"label\"] = 1\n",
    "set1_machine[\"label\"] = 0\n",
    "set2_human[\"label\"] = 1\n",
    "set2_machine[\"label\"] = 0\n",
    "\n",
    "dataset1 = pd.concat([set1_human, set1_machine], ignore_index=True)\n",
    "dataset2 = pd.concat([set2_human, set2_machine], ignore_index=True)\n",
    "\n",
    "# Convert integer lists to strings\n",
    "dataset1['txt'] = dataset1['txt'].apply(int_list_to_str)\n",
    "dataset2['txt'] = dataset2['txt'].apply(int_list_to_str)\n",
    "dataset1['prompt'] = dataset1['prompt'].apply(int_list_to_str)\n",
    "dataset2['prompt'] = dataset2['prompt'].apply(int_list_to_str)\n",
    "\n",
    "# Train/validation split\n",
    "train_data1, val_data1 = train_test_split(dataset1, test_size=0.2, random_state=42, stratify=dataset1[\"label\"])\n",
    "train_data2, val_data2 = train_test_split(dataset2, test_size=0.2, random_state=42, stratify=dataset2[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06f56e6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>txt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49944</th>\n",
       "      <td>1481 2430 4780 17 86 1607 68 70 1724 1722 2729...</td>\n",
       "      <td>10 1502 2157 1591 2850 15 1502 2157 1591 2451 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>1502 2332 1725 1479 3125 15 1493 2209 3034 150...</td>\n",
       "      <td>76 1549 81 10 87 1640 1586 2325 1559 1569 76 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36306</th>\n",
       "      <td>1602 2158 1944 2437 68 2607 2234 17 1487 1574 ...</td>\n",
       "      <td>76 4356 1764 76 1515 1487 1479 1616 1500 1574 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>1479 1845 2633 1831 1479 3573 1491 2329 2995 1...</td>\n",
       "      <td>13 1520 1678 1479 2025 1557 1502 34 1518 13 15...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100102</th>\n",
       "      <td>2571 17 1514 74 1620 1493 3943 2035 1641 2396 ...</td>\n",
       "      <td>1518 3300 1656 4429 15 1520 4630 2145 2038 394...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   prompt  \\\n",
       "49944   1481 2430 4780 17 86 1607 68 70 1724 1722 2729...   \n",
       "587     1502 2332 1725 1479 3125 15 1493 2209 3034 150...   \n",
       "36306   1602 2158 1944 2437 68 2607 2234 17 1487 1574 ...   \n",
       "6573    1479 1845 2633 1831 1479 3573 1491 2329 2995 1...   \n",
       "100102  2571 17 1514 74 1620 1493 3943 2035 1641 2396 ...   \n",
       "\n",
       "                                                      txt  label  \n",
       "49944   10 1502 2157 1591 2850 15 1502 2157 1591 2451 ...      1  \n",
       "587     76 1549 81 10 87 1640 1586 2325 1559 1569 76 1...      1  \n",
       "36306   76 4356 1764 76 1515 1487 1479 1616 1500 1574 ...      1  \n",
       "6573    13 1520 1678 1479 2025 1557 1502 34 1518 13 15...      1  \n",
       "100102  1518 3300 1656 4429 15 1520 4630 2145 2038 394...      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d69d14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize input data using Bag-of-Words representation\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X_train1 = vectorizer.fit_transform(train_data1['txt']).toarray()\n",
    "y_train1 = train_data1[\"label\"].values\n",
    "X_val1 = vectorizer.transform(val_data1['txt']).toarray()\n",
    "y_val1 = val_data1[\"label\"].values\n",
    "\n",
    "X_train2 = vectorizer.fit_transform(train_data2['txt']).toarray()\n",
    "y_train2 = train_data2[\"label\"].values\n",
    "X_val2 = vectorizer.transform(val_data2['txt']).toarray()\n",
    "y_val2 = val_data2[\"label\"].values\n",
    "\n",
    "X_train3 = vectorizer.fit_transform(train_data1['prompt']).toarray()\n",
    "y_train3 = train_data1[\"label\"].values\n",
    "X_val3 = vectorizer.transform(val_data1['prompt']).toarray()\n",
    "y_val3 = val_data1[\"label\"].values\n",
    "\n",
    "X_train4 = vectorizer.fit_transform(train_data2['prompt']).toarray()\n",
    "y_train4 = train_data2[\"label\"].values\n",
    "X_val4 = vectorizer.transform(val_data2['prompt']).toarray()\n",
    "y_val4 = val_data2[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8607080f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a7311\\.conda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\a7311\\.conda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TXT:\n",
      "\n",
      "Domain1 Validation Accuracy: 0.9803703850576991\n",
      "Domain2 Validation Accuracy: 0.8\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a7311\\.conda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\PROMPT:\n",
      "\n",
      "Domain1 Validation Accuracy: 0.9718047349010588\n",
      "Domain2 Validation Accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression model\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train1, y_train1)\n",
    "\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train2, y_train2)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_val1 = model1.predict(X_val1)\n",
    "y_pred_val2 = model2.predict(X_val2)\n",
    "\n",
    "print(\"\\nTXT:\\n\")\n",
    "print(\"Domain1 Validation Accuracy:\", accuracy_score(y_val1, y_pred_val1))\n",
    "print(\"Domain2 Validation Accuracy:\", accuracy_score(y_val2, y_pred_val2))\n",
    "print(\"\\n\" + \"-\" * 40 + \"\\n\")\n",
    "\n",
    "# Prompt fit\n",
    "model3 = LogisticRegression()\n",
    "model3.fit(X_train3, y_train3)\n",
    "\n",
    "model4 = LogisticRegression()\n",
    "model4.fit(X_train4, y_train4)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_val3 = model3.predict(X_val3)\n",
    "y_pred_val4 = model4.predict(X_val4)\n",
    "\n",
    "print(\"\\nPROMPT:\\n\")\n",
    "print(\"Domain1 Validation Accuracy:\", accuracy_score(y_val3, y_pred_val3))\n",
    "print(\"Domain2 Validation Accuracy:\", accuracy_score(y_val4, y_pred_val4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ff756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
