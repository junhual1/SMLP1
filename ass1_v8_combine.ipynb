{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 13:18:05.873802: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-25 13:18:05.915790: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-25 13:18:06.969613: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 13:18:08.817496: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-25 13:18:08.956124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-25 13:18:08.956587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "from gensim.models import Word2Vec\n",
    "from keras import layers\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout, Layer\n",
    "from tensorflow.keras.layers import Embedding, Input, GlobalAveragePooling1D, Dense, Concatenate\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "NUM_TOKEN = 5000\n",
    "MAX_PRO_LEN = 64\n",
    "MAX_TXT_LEN = 256\n",
    "NO_EPO = 60\n",
    "NO_BAT = 128\n",
    "CLS = 5001\n",
    "SEP = 5002\n",
    "PAD_ID = 0\n",
    "\n",
    "MACHINE_1_P = \"./data/set1_machine.json\"\n",
    "HUMAN_1_P = \"./data/set1_human.json\"\n",
    "MACHINE_2_P = \"./data/set2_machine.json\"\n",
    "HUMAN_2_P = \"./data/set2_human.json\"\n",
    "TEST_P = \"./data/test.json\"\n",
    "RANDOM_SEED = 42\n",
    "MACHINE_IND = 0\n",
    "HUMAN_IND = 1\n",
    "TEST_FRA = 0.2\n",
    "\n",
    "class DomainData:\n",
    "    \"\"\"\n",
    "    train_test_split, pad_sequence, class_weight\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def t_t_spli(self, test_size, random_state):\n",
    "        self.random_state = random_state\n",
    "        self.train_x, self.test_x, self.train_y, self.test_y = train_test_split(self.x, self.y, test_size=test_size, stratify = self.y, random_state = random_state)\n",
    "        self.train_x = self.train_x.reset_index(drop=True)\n",
    "        self.train_y = self.train_y.reset_index(drop=True)\n",
    "        self.test_x = self.test_x.reset_index(drop=True)\n",
    "        self.test_y = self.test_y.reset_index(drop=True)\n",
    "        \n",
    "    def add_sep(self):\n",
    "        self.x[\"prompt\"] = self.x.apply(lambda x: [i+1 for i in x[\"prompt\"]] , axis = 1)\n",
    "        self.x[\"prompt\"] = self.x.apply(lambda x: [CLS] + x[\"prompt\"] , axis = 1)\n",
    "        self.x[\"prompt\"] = self.x.apply(lambda x: x[\"prompt\"] + [SEP] if len(x[\"prompt\"])<MAX_PRO_LEN else x[\"prompt\"][:MAX_PRO_LEN-1] + [SEP], axis = 1)\n",
    "\n",
    "        self.x[\"txt\"] = self.x.apply(lambda x: [i+1 for i in x[\"txt\"]] , axis = 1)\n",
    "        self.x[\"txt\"] = self.x.apply(lambda x: [CLS] + x[\"txt\"] , axis = 1)\n",
    "        self.x[\"txt\"] = self.x.apply(lambda x: x[\"txt\"] + [SEP] if len(x[\"prompt\"])<MAX_TXT_LEN else x[\"txt\"][:MAX_TXT_LEN-1] + [SEP], axis = 1)\n",
    "        \n",
    "    \n",
    "    def add_padding(self, padding, prompt_len, txt_len):\n",
    "        self.train_prompt = self.train_x[\"prompt\"]\n",
    "        self.train_txt = self.train_x[\"txt\"]\n",
    "        self.train_label = self.train_y.to_numpy()\n",
    "        self.test_prompt = self.test_x[\"prompt\"]\n",
    "        self.test_txt = self.test_x[\"txt\"]\n",
    "        self.test_label = self.test_y.to_numpy()\n",
    "        unique_classes = np.unique(self.train_label)\n",
    "        class_weights = class_weight.compute_class_weight(\"balanced\", classes=unique_classes, y=self.train_y)\n",
    "        self.class_weights = dict(zip(unique_classes, class_weights))\n",
    "        \n",
    "        self.prompt_len = prompt_len\n",
    "        self.txt_len = txt_len\n",
    "        \n",
    "        self.train_prompt = pad_sequences(self.train_prompt, padding=padding, maxlen=prompt_len, value=PAD_ID)\n",
    "        self.train_txt = pad_sequences(self.train_txt, padding=padding, maxlen=txt_len, value=PAD_ID)\n",
    "        self.test_prompt = pad_sequences(self.test_prompt, padding=padding, maxlen=prompt_len, value=PAD_ID)\n",
    "        self.test_txt = pad_sequences(self.test_txt, padding=padding, maxlen=txt_len, value=PAD_ID)\n",
    "        \n",
    "        \n",
    "    def down_sampling(self):\n",
    "        mac_ind = self.train_y[self.train_y == MACHINE_IND].index.to_list()\n",
    "        hum_ind = self.train_y[self.train_y == HUMAN_IND].index.to_list()\n",
    "        lower = min(len(mac_ind), len(hum_ind))\n",
    "        sel_lit = mac_ind[:lower] + hum_ind[:lower]\n",
    "        self.train_x = self.train_x.iloc[sel_lit]\n",
    "        self.train_y = self.train_y.iloc[sel_lit]\n",
    "        random.shuffle(sel_lit)\n",
    "\n",
    "    def over_sampling(self, upper_fra):\n",
    "        mac_ind = self.train_y[self.train_y == MACHINE_IND].index.to_list()\n",
    "        hum_ind = self.train_y[self.train_y == HUMAN_IND].index.to_list()\n",
    "        lower = min(len(mac_ind), len(hum_ind))\n",
    "        if lower == len(mac_ind):\n",
    "            upper = int(lower*upper_fra) if lower*upper_fra < len(hum_ind) else len(hum_ind)\n",
    "            major = hum_ind[:upper]\n",
    "            minor = mac_ind[:lower]\n",
    "    \n",
    "        else:\n",
    "            upper = int(lower*upper_fra) if lower*upper_fra < len(mac_ind) else len(mac_ind)\n",
    "            major = mac_ind[:upper]\n",
    "            minor = hum_ind[:lower]\n",
    "        \n",
    "        add_n = upper - lower\n",
    "        oversampled = []\n",
    "        while(len(oversampled) < add_n):\n",
    "            oversampled.append(random.choice(mac_ind))\n",
    "        sel_lit = major + minor + oversampled\n",
    "        random.shuffle(sel_lit)\n",
    "        \n",
    "        self.train_x = self.train_x.iloc[sel_lit]\n",
    "        self.train_y = self.train_y.iloc[sel_lit]\n",
    "    \n",
    "    def test_down(self, frac = 1):\n",
    "        mac_ind = self.test_y[self.test_y == MACHINE_IND].index.to_list()\n",
    "        hum_ind = self.test_y[self.test_y == HUMAN_IND].index.to_list()\n",
    "        lower = min(len(mac_ind), len(hum_ind))\n",
    "        if frac > 1:\n",
    "            sel_lit = mac_ind[:lower] + hum_ind[:int(lower/frac)]\n",
    "        else:\n",
    "            sel_lit = mac_ind[:int(lower*frac)] + hum_ind[:lower]\n",
    "        self.test_x = self.test_x.iloc[sel_lit]\n",
    "        self.test_y = self.test_y.iloc[sel_lit]\n",
    "        random.shuffle(sel_lit)\n",
    "    \n",
    "    def word2vec(self, vector_size = 100, min_count = 1, file_name = None, model = None):\n",
    "        if model:\n",
    "            self.w2v_model = model\n",
    "        elif file_name:\n",
    "            self.w2v_model = Word2Vec.load(file_name)\n",
    "        else:\n",
    "            w2v_prompt = []\n",
    "            for i in self.train_prompt:\n",
    "                w2v_prompt.append(i[np.nonzero(i)])\n",
    "\n",
    "            w2v_txt = []\n",
    "            for i in self.train_txt:\n",
    "                w2v_txt.append(i[np.nonzero(i)])\n",
    "\n",
    "            w2v_train = [list(w2v_prompt[i]) + list(w2v_txt[i]) for i in range(len(self.train_prompt))]\n",
    "            print(\"text merged\")\n",
    "            sentences = [list(map(str, doc)) for doc in w2v_train]\n",
    "            sentences.append(range(NUM_TOKEN))\n",
    "            self.w2v_model = Word2Vec(sentences, vector_size=100, min_count = 1)\n",
    "        self.train_prompt = np.array([np.mean([self.w2v_model.wv[i] for i in j], axis=0) for j in self.train_prompt])\n",
    "        self.train_txt = np.array([np.mean([self.w2v_model.wv[i] for i in j], axis=0) for j in self.train_txt])\n",
    "        self.test_prompt = np.array([np.mean([self.w2v_model.wv[i] for i in j], axis=0) for j in self.test_prompt])\n",
    "        self.test_txt = np.array([np.mean([self.w2v_model.wv[i] for i in j], axis=0) for j in self.test_txt])\n",
    "        \n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    # Calculate precision and recall\n",
    "    tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)))\n",
    "    fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)))\n",
    "    fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)))\n",
    "    precision = tp / (tp + fp + backend.epsilon())\n",
    "    recall = tp / (tp + fn + backend.epsilon())\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1_score = 2 * precision * recall / (precision + recall + backend.epsilon())\n",
    "    \n",
    "    # Return negative F1 score as the loss (to minimize it)\n",
    "    return -f1_score\n",
    "\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\"), \n",
    "             Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class TokenAndPositionEmbedding(Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience = 3)\n",
    "random.seed(RANDOM_SEED)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "if len(tf.config.list_physical_devices('GPU')):\n",
    "    tf.config.list_physical_devices('GPU')\n",
    "    print(\"Using GPU\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain 1: LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text merged\n"
     ]
    }
   ],
   "source": [
    "vector_size = 150\n",
    "\n",
    "## _______________ Read data from domain 1 _______________\n",
    "man_1_df = pd.read_json(HUMAN_1_P)\n",
    "man_1_df[\"label\"] = HUMAN_IND\n",
    "mac_1_df = pd.read_json(MACHINE_1_P).drop(\"machine_id\", axis = 1)\n",
    "mac_1_df[\"label\"] = MACHINE_IND\n",
    "domain_1_df = pd.concat([man_1_df, mac_1_df])\n",
    "\n",
    "domain_1 = DomainData(domain_1_df[[\"prompt\", \"txt\"]], domain_1_df[\"label\"])\n",
    "domain_1.t_t_spli(TEST_FRA, RANDOM_SEED)\n",
    "# domain_1.over_sampling(1.6)\n",
    "domain_1.test_down()\n",
    "domain_1.add_padding('post', MAX_PRO_LEN, MAX_TXT_LEN)\n",
    "# domain_1.word2vec(vector_size, 1, \"Word2Vec_1.model\")\n",
    "domain_1.word2vec(vector_size, 1)\n",
    "domain_1.w2v_model.save(\"Word2Vec_1.model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1] [0 0 0 ... 1 1 1]\n",
      "Domain 1 -- F1 score on the test data:  0.8587650816181689\n",
      "confusion matrix: \n",
      " [[596 104]\n",
      " [ 95 605]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Train a logistic regression model on the training data\n",
    "clf = LogisticRegression(class_weight=domain_1.class_weights)\n",
    "clf.fit(domain_1.train_txt, domain_1.train_label)\n",
    "with open(\"lr_d1_v2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clf, f)\n",
    "y_pred = clf.predict(domain_1.test_txt)\n",
    "\n",
    "# Calculate the F1 score for the predictions\n",
    "f1 = f1_score(domain_1.test_label, y_pred)\n",
    "\n",
    "print(domain_1.test_label, y_pred)\n",
    "\n",
    "print(\"Domain 1 -- F1 score on the test data: \", f1)\n",
    "print(\"confusion matrix: \\n\", confusion_matrix(domain_1.test_label, y_pred))\n",
    "\n",
    "# 32/29: 100, 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain 2: transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_fra = 1.6\n",
    "weight_fra = 300\n",
    "\n",
    "## _______________ Read data from domain 1 _______________\n",
    "man_1_df = pd.read_json(HUMAN_1_P)\n",
    "man_1_df[\"label\"] = HUMAN_IND\n",
    "mac_1_df = pd.read_json(MACHINE_1_P).drop(\"machine_id\", axis = 1)\n",
    "mac_1_df[\"label\"] = MACHINE_IND\n",
    "domain_1_df = pd.concat([man_1_df, mac_1_df])\n",
    "\n",
    "domain_1 = DomainData(domain_1_df[[\"prompt\", \"txt\"]], domain_1_df[\"label\"])\n",
    "domain_1.t_t_spli(TEST_FRA, RANDOM_SEED)\n",
    "# domain_1.down_sampling()\n",
    "domain_1.add_padding('post', MAX_PRO_LEN, MAX_TXT_LEN)\n",
    "\n",
    "## _______________ Read data from domain 2 _______________\n",
    "man_2_df = pd.read_json(HUMAN_2_P)\n",
    "man_2_df[\"label\"] = HUMAN_IND\n",
    "mac_2_df = pd.read_json(MACHINE_2_P).drop(\"machine_id\", axis = 1)\n",
    "mac_2_df[\"label\"] = MACHINE_IND\n",
    "domain_2_df = pd.concat([man_2_df, mac_2_df])\n",
    "\n",
    "domain_2 = DomainData(domain_2_df[[\"prompt\", \"txt\"]], domain_2_df[\"label\"])\n",
    "domain_2.t_t_spli(TEST_FRA, RANDOM_SEED)\n",
    "# domain_2.over_sampling(over_fra)\n",
    "domain_2.test_down()\n",
    "domain_2.add_padding('post', MAX_PRO_LEN, MAX_TXT_LEN)\n",
    "\n",
    "\n",
    "\n",
    "## _______________ weight data _______________\n",
    "sample_weight_1 = np.ones(len(domain_1.train_label))\n",
    "sample_weight_2 = np.ones(len(domain_2.train_label))\n",
    "sample_weight_2 *= weight_fra\n",
    "sample_weight = np.concatenate([sample_weight_1, sample_weight_2])\n",
    "\n",
    "train_prompt = np.concatenate([domain_1.train_prompt, domain_2.train_prompt])\n",
    "train_txt = np.concatenate([domain_1.train_txt, domain_2.train_txt])\n",
    "train_label = np.concatenate([domain_1.train_label, domain_2.train_label])\n",
    "\n",
    "data = list(zip(train_prompt, train_txt, train_label, sample_weight))\n",
    "random.shuffle(data)\n",
    "\n",
    "train_prompt, train_txt, train_label, sample_weight = zip(*data)\n",
    "train_prompt = np.array(train_prompt)\n",
    "train_txt = np.array(train_txt)\n",
    "train_label = np.array(train_label)\n",
    "sample_weight = np.array(sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 13:18:18.175511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-25 13:18:18.176312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-25 13:18:18.177003: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-25 13:18:18.927917: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-25 13:18:18.928776: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-25 13:18:18.928789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-25 13:18:18.929454: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-25 13:18:18.929491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3383 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 13:18:34.105513: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-04-25 13:18:34.485055: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x4d68f240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-25 13:18:34.485100: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2023-04-25 13:18:34.490559: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-25 13:18:34.649529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-04-25 13:18:34.765882: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - ETA: 0s - loss: 0.9150 - accuracy: 0.9330 - f1_loss: -0.9592WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 113s 168ms/step - loss: 0.9150 - accuracy: 0.9330 - f1_loss: -0.9592 - val_loss: 0.7111 - val_accuracy: 0.9808 - val_f1_loss: -0.9901\n",
      "Epoch 2/60\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.6449 - accuracy: 0.9632 - f1_loss: -0.9805WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 74s 117ms/step - loss: 0.6449 - accuracy: 0.9632 - f1_loss: -0.9805 - val_loss: 1.0922 - val_accuracy: 0.9701 - val_f1_loss: -0.9847\n",
      "Epoch 3/60\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.3100 - accuracy: 0.9718 - f1_loss: -0.9855WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 72s 114ms/step - loss: 0.3100 - accuracy: 0.9718 - f1_loss: -0.9855 - val_loss: 0.6779 - val_accuracy: 0.9731 - val_f1_loss: -0.9862\n",
      "Epoch 4/60\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.9763 - f1_loss: -0.9878WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 72s 114ms/step - loss: 0.1241 - accuracy: 0.9763 - f1_loss: -0.9878 - val_loss: 0.9536 - val_accuracy: 0.9754 - val_f1_loss: -0.9873\n",
      "Epoch 5/60\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.1163 - accuracy: 0.9748 - f1_loss: -0.9869WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 70s 110ms/step - loss: 0.1163 - accuracy: 0.9748 - f1_loss: -0.9869 - val_loss: 0.5659 - val_accuracy: 0.9775 - val_f1_loss: -0.9883\n",
      "Epoch 6/60\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 0.9831 - f1_loss: -0.9913WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 69s 109ms/step - loss: 0.0559 - accuracy: 0.9831 - f1_loss: -0.9913 - val_loss: 0.5870 - val_accuracy: 0.9830 - val_f1_loss: -0.9912\n",
      "Epoch 7/60\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9867 - f1_loss: -0.9931WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 71s 112ms/step - loss: 0.0416 - accuracy: 0.9867 - f1_loss: -0.9931 - val_loss: 1.0345 - val_accuracy: 0.9835 - val_f1_loss: -0.9914\n",
      "Epoch 8/60\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9893 - f1_loss: -0.9945WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 72s 114ms/step - loss: 0.0322 - accuracy: 0.9893 - f1_loss: -0.9945 - val_loss: 1.2682 - val_accuracy: 0.9842 - val_f1_loss: -0.9918\n",
      "Epoch 9/60\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9908 - f1_loss: -0.9953WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 71s 113ms/step - loss: 0.0259 - accuracy: 0.9908 - f1_loss: -0.9953 - val_loss: 1.4538 - val_accuracy: 0.9846 - val_f1_loss: -0.9920\n",
      "Epoch 10/60\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9927 - f1_loss: -0.9962WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 70s 111ms/step - loss: 0.0204 - accuracy: 0.9927 - f1_loss: -0.9962 - val_loss: 1.5499 - val_accuracy: 0.9855 - val_f1_loss: -0.9925\n",
      "Epoch 11/60\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9936 - f1_loss: -0.9967WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 69s 109ms/step - loss: 0.0181 - accuracy: 0.9936 - f1_loss: -0.9967 - val_loss: 1.6592 - val_accuracy: 0.9848 - val_f1_loss: -0.9921\n",
      "Epoch 12/60\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9946 - f1_loss: -0.9972WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 69s 108ms/step - loss: 0.0162 - accuracy: 0.9946 - f1_loss: -0.9972 - val_loss: 1.0097 - val_accuracy: 0.9859 - val_f1_loss: -0.9927\n",
      "Epoch 13/60\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9940 - f1_loss: -0.9969WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 69s 109ms/step - loss: 0.0168 - accuracy: 0.9940 - f1_loss: -0.9969 - val_loss: 1.5653 - val_accuracy: 0.9852 - val_f1_loss: -0.9923\n",
      "Epoch 14/60\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9967 - f1_loss: -0.9983WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 69s 109ms/step - loss: 0.0094 - accuracy: 0.9967 - f1_loss: -0.9983 - val_loss: 1.7006 - val_accuracy: 0.9857 - val_f1_loss: -0.9926\n",
      "Epoch 15/60\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.1918 - accuracy: 0.9876 - f1_loss: -0.9935WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 70s 110ms/step - loss: 0.1918 - accuracy: 0.9876 - f1_loss: -0.9935 - val_loss: 0.8795 - val_accuracy: 0.9816 - val_f1_loss: -0.9905\n",
      "Epoch 16/60\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.1471 - accuracy: 0.9845 - f1_loss: -0.9920WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 70s 110ms/step - loss: 0.1471 - accuracy: 0.9845 - f1_loss: -0.9920 - val_loss: 0.9347 - val_accuracy: 0.9822 - val_f1_loss: -0.9906\n",
      "Epoch 17/60\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9921 - f1_loss: -0.9959WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 69s 109ms/step - loss: 0.0215 - accuracy: 0.9921 - f1_loss: -0.9959 - val_loss: 1.2357 - val_accuracy: 0.9852 - val_f1_loss: -0.9922\n",
      "Model Saved: trans_model_weighted.h5\n",
      "Model Loaded: trans_model_weighted.h5\n",
      "loss:  0.32024431228637695\n",
      "accuracy 0.875\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "[[20  0]\n",
      " [ 5 15]]\n",
      "f1-score:  0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout, Layer\n",
    "from tensorflow.keras.layers import Embedding, Input, GlobalAveragePooling1D, Dense, Concatenate\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\"), \n",
    "             Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class TokenAndPositionEmbedding(Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "\n",
    "vocab_size = 5000  # Only consider the top 20k words\n",
    "embed_dim = 128  # Embedding size for each token\n",
    "num_heads = 8  # Number of attention heads\n",
    "ff_dim = 20  # Hidden layer size in feed forward network inside transformer\n",
    "epo_size = NO_EPO\n",
    "batch_size = 128\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "\n",
    "# define model\n",
    "inputs_p = Input(shape=(MAX_PRO_LEN,))\n",
    "embedding_layer = TokenAndPositionEmbedding(MAX_PRO_LEN, vocab_size, embed_dim)\n",
    "x = embedding_layer(inputs_p)\n",
    "x = transformer_block(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(20, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "\n",
    "# define model\n",
    "inputs_t = Input(shape=(MAX_TXT_LEN,))\n",
    "embedding_layer = TokenAndPositionEmbedding(MAX_TXT_LEN, vocab_size, embed_dim)\n",
    "y = embedding_layer(inputs_t)\n",
    "y = transformer_block(y)\n",
    "y = GlobalAveragePooling1D()(y)\n",
    "y = Dropout(0.1)(y)\n",
    "y = Dense(20, activation=\"relu\")(y)\n",
    "y = Dropout(0.1)(y)\n",
    "\n",
    "\n",
    "# Concatenate outputs from prompt and text models\n",
    "merged = Concatenate()([x, y])\n",
    "merged = Dense(units=64, activation='relu')(merged)\n",
    "merged = Dense(20, activation=\"relu\")(merged)\n",
    "outputs = Dense(units=1, activation='sigmoid')(merged)\n",
    "trans_model_2 = Model(inputs=[inputs_p, inputs_t], outputs=outputs)\n",
    "\n",
    "# Compile and train\n",
    "trans_model_2.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\", f1_loss])\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('trans_model_weighted.h5', monitor='val_loss', save_best_only=True)\n",
    "trans_model_2.fit([train_prompt, train_txt], train_label, epochs=epo_size, batch_size=batch_size, sample_weight = sample_weight, validation_split=0.2, callbacks = [callback, model_checkpoint])\n",
    "print(\"Model Saved: trans_model_weighted.h5\")\n",
    "\n",
    "trans_model_2 = tf.keras.models.load_model(\"trans_model_weighted.h5\", custom_objects={ 'f1_loss': f1_loss, 'TransformerBlock': TransformerBlock, 'TokenAndPositionEmbedding':TokenAndPositionEmbedding })\n",
    "print(\"Model Loaded: trans_model_weighted.h5\")\n",
    "loss, accuracy, f1 = trans_model_2.evaluate([domain_2.test_prompt, domain_2.test_txt], domain_2.test_label, verbose=False)\n",
    "print(\"loss: \", loss)\n",
    "print(\"accuracy\", accuracy)\n",
    "trans_2_pre_rnn = trans_model_2.predict([domain_2.test_prompt, domain_2.test_txt])\n",
    "trans_2_pre_rnn = np.round(trans_2_pre_rnn).flatten()\n",
    "confusion = confusion_matrix(domain_2.test_label, trans_2_pre_rnn)\n",
    "# trans_2_pre_rnn = [0 if i.flatten()[0] > i.flatten()[1] else 1 for i in trans_2_pre_rnn]\n",
    "# confusion = confusion_matrix(domain_2.test_label, trans_2_pre_rnn)\n",
    "print(confusion)\n",
    "f1 = f1_score(domain_2.test_label, trans_2_pre_rnn)\n",
    "print(\"f1-score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "DOMAIN_SPL = 600\n",
    "\n",
    "\n",
    "DOMAIN_SPL = 600\n",
    "\n",
    "DOMAIN_SPL = 600\n",
    "\n",
    "w2v_model_1 = Word2Vec.load(\"Word2Vec_1.model\")\n",
    "test_df = pd.read_json(TEST_P)\n",
    "test_prompt = pad_sequences(test_df[\"prompt\"], padding=\"post\", maxlen=MAX_PRO_LEN)\n",
    "test_txt = pad_sequences(test_df[\"txt\"], padding=\"post\", maxlen=MAX_TXT_LEN)\n",
    "\n",
    "test_txt_w2v = list(pad_sequences(test_df[\"txt\"], padding=\"post\", maxlen=MAX_TXT_LEN))\n",
    "test_txt_w2v = np.array([np.mean([w2v_model_1.wv[i] for i in j], axis=0) for j in test_txt_w2v[:DOMAIN_SPL]])\n",
    "with open(\"lr_d1_v1.pkl\", \"rb\") as f:\n",
    "    model_1 = pickle.load(f)\n",
    "model_2 = tf.keras.models.load_model(\"trans_model_weighted.h5\", custom_objects={ 'f1_loss': f1_loss, 'TransformerBlock': TransformerBlock, 'TokenAndPositionEmbedding':TokenAndPositionEmbedding })\n",
    "\n",
    "\n",
    "\n",
    "pred_1 = model_1.predict(test_txt_w2v).tolist()\n",
    "pred_2 = model_2.predict([test_prompt[DOMAIN_SPL:], test_txt[DOMAIN_SPL:]]).tolist()\n",
    "\n",
    "pred_2 = [int(i) for i in np.round(pred_2).flatten()]\n",
    "\n",
    "pred = pred_1 + pred_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(pred)\n",
    "pred_df.columns = [\"Predicted\"]\n",
    "pred_df.index.names = ['Id']\n",
    "\n",
    "pred_df.to_csv(\"./data/result8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference:  84\n",
      "491\n",
      "465\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0\n",
      " 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0]\n",
      "[601, 603, 624, 629, 632, 638, 639, 647, 654, 656, 658, 659, 667, 668, 669, 670, 671, 676, 677, 683, 694, 699, 704, 714, 716, 721, 728, 734, 743, 744, 753, 760, 762, 765, 767, 768, 777, 786, 790, 804, 805, 809, 811, 815, 816, 819, 820, 830, 836, 847, 849, 854, 856, 865, 869, 870, 872, 875, 878, 898, 900, 901, 904, 908, 911, 915, 921, 926, 929, 937, 938, 941, 943, 947, 957, 959, 963, 968, 979, 981, 987, 994, 997, 998]\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"./data/result7.csv\")\n",
    "df2 = pd.read_csv(\"./data/result8.csv\")\n",
    "\n",
    "df1[\"pred_2\"] = df2[\"Predicted\"]\n",
    "df1[\"compare\"] = df1.apply(lambda x: 1 if int(x[\"pred_2\"] != x[\"Predicted\"]) else 0, axis=1)\n",
    "\n",
    "print(\"Difference: \", sum(df1[\"compare\"].values.tolist()))\n",
    "\n",
    "print(sum(df1[\"Predicted\"].to_numpy()))\n",
    "print(sum(df1[\"pred_2\"].to_numpy()))\n",
    "\n",
    "print(df1[\"compare\"].values)\n",
    "dis_m = []\n",
    "for i in range(len(df1[\"compare\"].values)):\n",
    "    if df1[\"compare\"][i] != 0:\n",
    "        dis_m.append(i)\n",
    "print(dis_m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
