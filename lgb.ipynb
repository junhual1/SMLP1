{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "# Load dataset\n",
    "def load_dataset(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Convert integer list to string\n",
    "def int_list_to_str(int_list):\n",
    "    return ' '.join(map(str, int_list))\n",
    "\n",
    "\n",
    "# Load data\n",
    "set1_human = load_dataset(\"./data/set1_human.json\")\n",
    "set1_machine = load_dataset(\"./data/set1_machine.json\")\n",
    "set2_human = load_dataset(\"./data/set2_human.json\")\n",
    "set2_machine = load_dataset(\"./data/set2_machine.json\")\n",
    "\n",
    "# Label data and combine\n",
    "set1_human[\"label\"] = 1\n",
    "set1_machine[\"label\"] = 0\n",
    "set2_human[\"label\"] = 1\n",
    "set2_machine[\"label\"] = 0\n",
    "\n",
    "dataset1 = pd.concat([set1_human, set1_machine], ignore_index=True)\n",
    "dataset2 = pd.concat([set2_human, set2_machine], ignore_index=True)\n",
    "\n",
    "# Convert integer lists to strings\n",
    "dataset1['txt'] = dataset1['txt'].apply(int_list_to_str)\n",
    "dataset2['txt'] = dataset2['txt'].apply(int_list_to_str)\n",
    "dataset1['prompt'] = dataset1['prompt'].apply(int_list_to_str)\n",
    "dataset2['prompt'] = dataset2['prompt'].apply(int_list_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataset = pd.concat([dataset1, dataset2], ignore_index=True)\n",
    "whole_dataset['combined'] = whole_dataset['txt'] + ' ' + whole_dataset['prompt']\n",
    "# # Word2Vec\n",
    "# all_text = [text.split() for text in whole_dataset['combined'].values]\n",
    "# word2vec_model = Word2Vec(all_text, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# # Save model\n",
    "# word2vec_model.save(\"word2vec.model\")\n",
    "\n",
    "# Load model\n",
    "word2vec_model = Word2Vec.load(\"word2vec.model\")\n",
    "\n",
    "def vectorize(dataset, word2vec_model, has_label=True):\n",
    "    X_prompt = dataset['prompt'].values\n",
    "    X_txt = dataset['txt'].values\n",
    "    X_prompt = [text.split() for text in X_prompt]\n",
    "    X_txt = [text.split() for text in X_txt]\n",
    "    # prompt may be empty, use zero vector to represent\n",
    "    X_prompt = np.array([np.mean([word2vec_model.wv[token] for token in tokens if token in word2vec_model.wv],\n",
    "                                 axis=0) if tokens else np.zeros(100) for tokens in X_prompt])\n",
    "    X_txt = np.array([np.mean([word2vec_model.wv[token] \n",
    "                               for token in tokens if token in word2vec_model.wv], axis=0) for tokens in X_txt])\n",
    "    promt_len = np.expand_dims(np.array([len(text.split()) for text in dataset['prompt'].values]), axis=1)\n",
    "    txt_len = np.expand_dims(np.array([len(text.split()) for text in dataset['txt'].values]), axis=1)\n",
    "    X = np.concatenate((X_prompt, X_txt, promt_len, txt_len), axis=1)\n",
    "    if has_label:\n",
    "        y = dataset['label'].values\n",
    "        return X, y\n",
    "    else:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done vectorize!\n"
     ]
    }
   ],
   "source": [
    "# Split dataset 1 and dataset 2\n",
    "dataset1_train, dataset1_test = train_test_split(\n",
    "    dataset1, test_size=0.2, random_state=90051)\n",
    "dataset2_train, dataset2_test = train_test_split(\n",
    "    dataset2, test_size=0.2, random_state=90051)\n",
    "\n",
    "# Preprocess dataset 1 and dataset 2\n",
    "X_train1, y_train1 = vectorize(dataset1_train, word2vec_model)\n",
    "X_test1, y_test1 = vectorize(dataset1_test, word2vec_model)\n",
    "X_train2, y_train2 = vectorize(dataset2_train, word2vec_model)\n",
    "X_test2, y_test2 = vectorize(dataset2_test, word2vec_model)\n",
    "X_train1_whole, y_train1_whole = vectorize(dataset1, word2vec_model)\n",
    "X_train2_whole, y_train2_whole = vectorize(dataset2, word2vec_model)\n",
    "print(\"done vectorize!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary on dataset 1 test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.85       691\n",
      "           1       0.99      1.00      1.00     24526\n",
      "\n",
      "    accuracy                           0.99     25217\n",
      "   macro avg       0.94      0.91      0.93     25217\n",
      "weighted avg       0.99      0.99      0.99     25217\n",
      "\n",
      "[[  567   124]\n",
      " [   69 24457]]\n",
      "\n",
      "*** Summary on dataset 2 test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.87        72\n",
      "           1       0.71      0.54      0.61        28\n",
      "\n",
      "    accuracy                           0.81       100\n",
      "   macro avg       0.77      0.73      0.74       100\n",
      "weighted avg       0.80      0.81      0.80       100\n",
      "\n",
      "[[66  6]\n",
      " [13 15]]\n"
     ]
    }
   ],
   "source": [
    "# Method 2: tansfer learning/ domain adaptation\n",
    "# Train a LightGBM model on dataset 1\n",
    "X_train1, y_train1 = vectorize(dataset1_train, word2vec_model)\n",
    "X_test1, y_test1 = vectorize(dataset1_test, word2vec_model)\n",
    "X_train2, y_train2 = vectorize(dataset2_train, word2vec_model)\n",
    "X_test2, y_test2 = vectorize(dataset2_test, word2vec_model)\n",
    "\n",
    "lgbm1 = LGBMClassifier(objective='binary', n_estimators=500, \n",
    "                       boosting_type='gbdt', is_unbalance=True,\n",
    "                       reg_alpha=0, reg_lambda=0.1)\n",
    "lgbm1.fit(X_train1, y_train1)\n",
    "\n",
    "# Train a LightGBM model on dataset 2 using the new labels\n",
    "lgbm2 = LGBMClassifier(objective='binary', n_estimators=500,\n",
    "                       boosting_type='gbdt', is_unbalance=True,\n",
    "                       reg_alpha=0.5, reg_lambda=1, learning_rate=0.01)\n",
    "lgbm2.fit(X_train2, y_train2, init_model=lgbm1)\n",
    "\n",
    "# Predict and evaluate on dataset 1 test set\n",
    "print(\"*** Summary on dataset 1 test set:\")\n",
    "y_pred1 = lgbm1.predict(X_test1)\n",
    "print(classification_report(y_test1, y_pred1))\n",
    "print(confusion_matrix(y_test1, y_pred1))\n",
    "\n",
    "# Predict and evaluate on dataset 2 test set\n",
    "print(\"\\n*** Summary on dataset 2 test set:\")\n",
    "y_pred2 = lgbm2.predict(X_test2)\n",
    "print(classification_report(y_test2, y_pred2))\n",
    "print(confusion_matrix(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to file: LGB_domain_adaption_l1l2_all_data.csv\n"
     ]
    }
   ],
   "source": [
    "# OUTPUT to CSV\n",
    "# use the whole dataset2 to train model2\n",
    "lgbm1 = LGBMClassifier(objective='binary', n_estimators=500,\n",
    "                       boosting_type='gbdt', is_unbalance=True,\n",
    "                       reg_alpha=0, reg_lambda=0.1)\n",
    "lgbm1.fit(X_train1_whole, y_train1_whole)\n",
    "\n",
    "lgbm2 = LGBMClassifier(objective='binary', n_estimators=500, \n",
    "                       boosting_type='gbdt', is_unbalance=True,\n",
    "                       reg_alpha=0.5, reg_lambda=1, learning_rate=0.01)\n",
    "lgbm2.fit(X_train2_whole, y_train2_whole, init_model=lgbm1)\n",
    "\n",
    "# Load test set\n",
    "test_data = load_dataset(\"./data/test.json\")\n",
    "test_data['txt'] = test_data['txt'].apply(int_list_to_str)\n",
    "test_data['prompt'] = test_data['prompt'].apply(int_list_to_str)\n",
    "test_data1 = test_data.iloc[:600]\n",
    "test_data2 = test_data.iloc[600:]\n",
    "\n",
    "# Preprocess test set\n",
    "X_test1 = vectorize(test_data1, word2vec_model, has_label=False)\n",
    "X_test2 = vectorize(test_data2, word2vec_model, has_label=False)\n",
    "\n",
    "y_pred1 = lgbm1.predict(X_test1)\n",
    "y_pred2 = lgbm2.predict(X_test2)\n",
    "\n",
    "# Combine predictions for both domains\n",
    "y_pred_test = np.concatenate([y_pred1, y_pred2])\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "output_df = pd.DataFrame(\n",
    "    {\"Id\": range(len(y_pred_test)), \"Predicted\": y_pred_test})\n",
    "filename = \"LGB_domain_adaption_l1l2_all_data.csv\"\n",
    "output_df.to_csv(filename, index=False)\n",
    "print(\"Predictions saved to file:\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best parameters found:  {'boosting_type': 'gbdt', 'is_unbalance': True, 'objective': 'binary', 'reg_alpha': 0, 'reg_lambda': 0}\n",
      "Best score found:  0.9960543531170402\n",
      "*** Summary on dataset 1 test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89       332\n",
      "           1       1.00      1.00      1.00     12277\n",
      "\n",
      "    accuracy                           0.99     12609\n",
      "   macro avg       0.95      0.94      0.95     12609\n",
      "weighted avg       0.99      0.99      0.99     12609\n",
      "\n",
      "[[  292    40]\n",
      " [   29 12248]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'objective': ['binary'],\n",
    "    'boosting_type': ['gbdt'],\n",
    "    'is_unbalance': [True],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1.0],  # L1 regularization\n",
    "    'reg_lambda': [0, 0.1, 0.5, 1.0]  # L2 regularization\n",
    "}\n",
    "\n",
    "lgbm = LGBMClassifier(n_estimators=500)\n",
    "grid_search = GridSearchCV(estimator=lgbm, param_grid=param_grid,\n",
    "                           cv=5, scoring='f1', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train1_whole, y_train1_whole)\n",
    "# Print the best parameters and corresponding score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best score found: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary on dataset 1 test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.85       691\n",
      "           1       0.99      1.00      1.00     24526\n",
      "\n",
      "    accuracy                           0.99     25217\n",
      "   macro avg       0.94      0.91      0.93     25217\n",
      "weighted avg       0.99      0.99      0.99     25217\n",
      "\n",
      "[[  567   124]\n",
      " [   69 24457]]\n"
     ]
    }
   ],
   "source": [
    "lgbm1 = LGBMClassifier(objective='binary', n_estimators=500,\n",
    "                       boosting_type='gbdt', is_unbalance=True,\n",
    "                       reg_alpha=0, reg_lambda=0.1)\n",
    "lgbm1.fit(X_train1, y_train1)\n",
    "# Evaluate on dataset 1 test set\n",
    "print(\"*** Summary on dataset 1 test set:\")\n",
    "y_pred1 = lgbm1.predict(X_test1)\n",
    "print(classification_report(y_test1, y_pred1))\n",
    "print(confusion_matrix(y_test1, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'learning_rate': 0.01, 'n_estimators': 500, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "*** Summary on dataset 2 test set (best model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86        72\n",
      "           1       0.67      0.50      0.57        28\n",
      "\n",
      "    accuracy                           0.79       100\n",
      "   macro avg       0.74      0.70      0.72       100\n",
      "weighted avg       0.78      0.79      0.78       100\n",
      "\n",
      "[[65  7]\n",
      " [14 14]]\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune lgbm1 on dataset 2 with a smaller learning rate\n",
    "# grid search for best alpha\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set up the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [500],\n",
    "    'learning_rate': [0.01],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1, 5, 10],\n",
    "    'reg_lambda': [0, 0.1, 0.5, 1, 5, 10]\n",
    "}\n",
    "\n",
    "# Create a LightGBM model for fine-tuning\n",
    "lgbm_finetuned = LGBMClassifier(objective='binary', boosting_type='gbdt', is_unbalance=True)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(lgbm_finetuned, param_grid, scoring='f1', cv=5)\n",
    "grid_search.fit(X_train2_whole, y_train2_whole, init_model=lgbm1)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found:\", best_params)\n",
    "\n",
    "# Train a new LightGBM model with the best parameters\n",
    "lgbm_best = LGBMClassifier(**best_params, objective='binary',\n",
    "                           boosting_type='gbdt', is_unbalance=True)\n",
    "lgbm_best.fit(X_train2, y_train2, init_model=lgbm1)\n",
    "\n",
    "# Predict and evaluate on dataset 2 test set\n",
    "print(\"*** Summary on dataset 2 test set (best model):\")\n",
    "y_pred2_best = lgbm_best.predict(X_test2)\n",
    "print(classification_report(y_test2, y_pred2_best))\n",
    "print(confusion_matrix(y_test2, y_pred2_best))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
