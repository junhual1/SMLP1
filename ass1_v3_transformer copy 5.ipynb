{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout, Layer, Embedding, Input, GlobalAveragePooling1D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "NUM_TOKEN = 5000\n",
    "MAX_PRO_LEN = 64\n",
    "MAX_TXT_LEN = 256\n",
    "NO_EPO = 60\n",
    "NO_BAT = 128\n",
    "\n",
    "MACHINE_1_P = \"./data/set1_machine.json\"\n",
    "HUMAN_1_P = \"./data/set1_human.json\"\n",
    "MACHINE_2_P = \"./data/set2_machine.json\"\n",
    "HUMAN_2_P = \"./data/set2_human.json\"\n",
    "TEST_P = \"./data/test.json\"\n",
    "RANDOM_SEED = 42\n",
    "MACHINE_IND = 0\n",
    "HUMAN_IND = 1\n",
    "TEST_FRA = 0.2\n",
    "\n",
    "\n",
    "class DomainData:\n",
    "    \"\"\"\n",
    "    Domain dataset contains data for traininig. \n",
    "    Featured with function train test split, padding, \n",
    "    downsampling, oversampling and rebalance test class weight.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        # inupts are (pd.Dataframe, pd.Series)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def t_t_spli(self, test_size, random_state):\n",
    "        ## train test split according to test fraction <test_size> and random state <random_state>\n",
    "        ## generated train_x / test_x are pd.Dataframe, train_y / test_y are pd.Series\n",
    "        self.random_state = random_state\n",
    "        self.train_x, self.test_x, self.train_y, self.test_y = train_test_split(\n",
    "            self.x, self.y, test_size=test_size, stratify=self.y, random_state=random_state)\n",
    "        self.train_x = self.train_x.reset_index(drop=True)\n",
    "        self.train_y = self.train_y.reset_index(drop=True)\n",
    "        self.test_x = self.test_x.reset_index(drop=True)\n",
    "        self.test_y = self.test_y.reset_index(drop=True)\n",
    "\n",
    "    def add_padding(self, padding, prompt_len, txt_len):\n",
    "        ## add padding of the given length\n",
    "        ## out put are np arraies\n",
    "        self.train_prompt = self.train_x[\"prompt\"]\n",
    "        self.train_txt = self.train_x[\"txt\"]\n",
    "        self.train_label = self.train_y.to_numpy()\n",
    "        self.test_prompt = self.test_x[\"prompt\"]\n",
    "        self.test_txt = self.test_x[\"txt\"]\n",
    "        self.test_label = self.test_y.to_numpy()\n",
    "        unique_classes = np.unique(self.train_label)\n",
    "        class_weights = class_weight.compute_class_weight(\n",
    "            \"balanced\", classes=unique_classes, y=self.train_y)\n",
    "        self.class_weights = dict(zip(unique_classes, class_weights))\n",
    "\n",
    "        self.prompt_len = prompt_len\n",
    "        self.txt_len = txt_len\n",
    "\n",
    "        self.train_prompt = pad_sequences(\n",
    "            self.train_prompt, padding=padding, maxlen=prompt_len)\n",
    "        self.train_txt = pad_sequences(\n",
    "            self.train_txt, padding=padding, maxlen=txt_len)\n",
    "        self.test_prompt = pad_sequences(\n",
    "            self.test_prompt, padding=padding, maxlen=prompt_len)\n",
    "        self.test_txt = pad_sequences(\n",
    "            self.test_txt, padding=padding, maxlen=txt_len)\n",
    "\n",
    "    def down_sampling(self):\n",
    "        ## down sample the majority calss to have same number of record compare to nimor class\n",
    "        mac_ind = self.train_y[self.train_y == MACHINE_IND].index.to_list()\n",
    "        hum_ind = self.train_y[self.train_y == HUMAN_IND].index.to_list()\n",
    "        lower = min(len(mac_ind), len(hum_ind))\n",
    "        sel_lit = mac_ind[:lower] + hum_ind[:lower]\n",
    "        self.train_x = self.train_x.iloc[sel_lit]\n",
    "        self.train_y = self.train_y.iloc[sel_lit]\n",
    "        random.shuffle(sel_lit)\n",
    "\n",
    "    def over_sampling(self, upper_fra):\n",
    "        ## over sampling the minority class with a fraction then \n",
    "        ### down sample the majority to have the same number of records\n",
    "        \n",
    "        # find index\n",
    "        mac_ind = self.train_y[self.train_y == MACHINE_IND].index.to_list()\n",
    "        hum_ind = self.train_y[self.train_y == HUMAN_IND].index.to_list()\n",
    "        lower = min(len(mac_ind), len(hum_ind))\n",
    "        if lower == len(mac_ind):\n",
    "            upper = int(lower*upper_fra) if lower * \\\n",
    "                upper_fra < len(hum_ind) else len(hum_ind)\n",
    "            major = hum_ind[:upper]\n",
    "            minor = mac_ind[:lower]\n",
    "        else:\n",
    "            upper = int(lower*upper_fra) if lower * \\\n",
    "                upper_fra < len(mac_ind) else len(mac_ind)\n",
    "            major = mac_ind[:upper]\n",
    "            minor = hum_ind[:lower]\n",
    "\n",
    "        # resampling\n",
    "        add_n = upper - lower\n",
    "        oversampled = []\n",
    "        while (len(oversampled) < add_n):\n",
    "            oversampled.append(random.choice(mac_ind))\n",
    "        sel_lit = major + minor + oversampled\n",
    "        random.shuffle(sel_lit)\n",
    "\n",
    "        self.train_x = self.train_x.iloc[sel_lit]\n",
    "        self.train_y = self.train_y.iloc[sel_lit]\n",
    "\n",
    "    def test_down(self, frac=1):\n",
    "        ## down sample the majority class in test sets to have same number of record with the minority class\n",
    "        mac_ind = self.test_y[self.test_y == MACHINE_IND].index.to_list()\n",
    "        hum_ind = self.test_y[self.test_y == HUMAN_IND].index.to_list()\n",
    "        lower = min(len(mac_ind), len(hum_ind))\n",
    "        if frac > 1:\n",
    "            sel_lit = mac_ind[:lower] + hum_ind[:int(lower/frac)]\n",
    "        else:\n",
    "            sel_lit = mac_ind[:int(lower*frac)] + hum_ind[:lower]\n",
    "        self.test_x = self.test_x.iloc[sel_lit]\n",
    "        self.test_y = self.test_y.iloc[sel_lit]\n",
    "        random.shuffle(sel_lit)\n",
    "\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    # Calculate precision and recall\n",
    "    tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)))\n",
    "    fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)))\n",
    "    fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)))\n",
    "    precision = tp / (tp + fp + backend.epsilon())\n",
    "    recall = tp / (tp + fn + backend.epsilon())\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1_score = 2 * precision * recall / \\\n",
    "        (precision + recall + backend.epsilon())\n",
    "\n",
    "    # Return negative F1 score as the loss (to minimize it)\n",
    "    return -f1_score\n",
    "\n",
    "\n",
    "# transformer / embedding block design/code from Bharath K\n",
    "# https://blog.paperspace.com/transformers-text-classification/\n",
    "\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, drop_rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\"),\n",
    "             Dense(embed_dim),]\n",
    "        )\n",
    "        self.dropout1 = Dropout(drop_rate)\n",
    "        self.dropout2 = Dropout(drop_rate)\n",
    "        self.lay_nor_1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.lay_nor_2 = LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.attention(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.lay_nor_1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.lay_nor_2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "class EmbeddingLayer(Layer):\n",
    "    def __init__(self, maxlen, NUM_TOKEN, embed_dim):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.token_emb = Embedding(input_dim=NUM_TOKEN, output_dim=embed_dim)\n",
    "        self.pos_emb = Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "random.seed(RANDOM_SEED)\n",
    "## using GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "if len(tf.config.list_physical_devices('GPU')):\n",
    "    tf.config.list_physical_devices('GPU')\n",
    "    print(\"Using GPU\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _______________ Read data from domain 1 _______________\n",
    "man_1_df = pd.read_json(HUMAN_1_P)\n",
    "man_1_df[\"label\"] = HUMAN_IND\n",
    "mac_1_df = pd.read_json(MACHINE_1_P).drop(\"machine_id\", axis=1)\n",
    "mac_1_df[\"label\"] = MACHINE_IND\n",
    "domain_1_df = pd.concat([man_1_df, mac_1_df])\n",
    "\n",
    "domain_1 = DomainData(domain_1_df[[\"prompt\", \"txt\"]], domain_1_df[\"label\"])\n",
    "domain_1.t_t_spli(TEST_FRA, RANDOM_SEED)\n",
    "domain_1.over_sampling(1.6)\n",
    "domain_1.test_down()\n",
    "domain_1.add_padding('post', MAX_PRO_LEN, MAX_TXT_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 02:54:58.528889: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-26 02:54:58.529445: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-26 02:54:58.530113: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-26 02:55:00.038590: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-26 02:55:00.039348: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-26 02:55:00.039365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-26 02:55:00.040058: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-26 02:55:00.040212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3383 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 02:55:04.985812: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-04-26 02:55:05.106773: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f973891ac70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-26 02:55:05.106811: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2023-04-26 02:55:05.117400: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-26 02:55:05.472454: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-04-26 02:55:05.575055: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 19s 223ms/step - loss: 0.3603 - accuracy: 0.8551 - f1_loss: -0.8566 - val_loss: 0.2710 - val_accuracy: 0.8917 - val_f1_loss: -0.8853\n",
      "Epoch 2/60\n",
      "56/56 [==============================] - 9s 166ms/step - loss: 0.2460 - accuracy: 0.8979 - f1_loss: -0.8949 - val_loss: 0.2036 - val_accuracy: 0.9174 - val_f1_loss: -0.9133\n",
      "Epoch 3/60\n",
      "56/56 [==============================] - 7s 131ms/step - loss: 0.1658 - accuracy: 0.9336 - f1_loss: -0.9325 - val_loss: 0.1835 - val_accuracy: 0.9342 - val_f1_loss: -0.9302\n",
      "Epoch 4/60\n",
      "56/56 [==============================] - 6s 104ms/step - loss: 0.0881 - accuracy: 0.9688 - f1_loss: -0.9681 - val_loss: 0.3021 - val_accuracy: 0.9068 - val_f1_loss: -0.8945\n",
      "Epoch 5/60\n",
      "56/56 [==============================] - 4s 76ms/step - loss: 0.0650 - accuracy: 0.9745 - f1_loss: -0.9746 - val_loss: 0.2566 - val_accuracy: 0.9330 - val_f1_loss: -0.9285\n",
      "Epoch 6/60\n",
      "56/56 [==============================] - 4s 63ms/step - loss: 0.0359 - accuracy: 0.9886 - f1_loss: -0.9886 - val_loss: 0.3096 - val_accuracy: 0.9459 - val_f1_loss: -0.9442\n",
      "Epoch 7/60\n",
      "56/56 [==============================] - 4s 67ms/step - loss: 0.0253 - accuracy: 0.9915 - f1_loss: -0.9914 - val_loss: 0.2579 - val_accuracy: 0.9397 - val_f1_loss: -0.9367\n",
      "Epoch 8/60\n",
      "56/56 [==============================] - 4s 80ms/step - loss: 0.0099 - accuracy: 0.9967 - f1_loss: -0.9967 - val_loss: 0.3949 - val_accuracy: 0.9453 - val_f1_loss: -0.9438\n",
      "Epoch 9/60\n",
      "56/56 [==============================] - 4s 65ms/step - loss: 0.0115 - accuracy: 0.9968 - f1_loss: -0.9969 - val_loss: 0.3145 - val_accuracy: 0.9431 - val_f1_loss: -0.9410\n",
      "Epoch 10/60\n",
      "56/56 [==============================] - 3s 59ms/step - loss: 0.0061 - accuracy: 0.9985 - f1_loss: -0.9985 - val_loss: 0.3045 - val_accuracy: 0.9420 - val_f1_loss: -0.9399\n",
      "Epoch 11/60\n",
      "56/56 [==============================] - 3s 57ms/step - loss: 0.0075 - accuracy: 0.9975 - f1_loss: -0.9975 - val_loss: 0.4745 - val_accuracy: 0.9353 - val_f1_loss: -0.9316\n",
      "Epoch 12/60\n",
      "56/56 [==============================] - 3s 53ms/step - loss: 0.0072 - accuracy: 0.9979 - f1_loss: -0.9979 - val_loss: 0.3732 - val_accuracy: 0.9431 - val_f1_loss: -0.9411\n",
      "Epoch 13/60\n",
      "56/56 [==============================] - 3s 61ms/step - loss: 0.0093 - accuracy: 0.9975 - f1_loss: -0.9974 - val_loss: 0.3729 - val_accuracy: 0.9459 - val_f1_loss: -0.9434\n",
      "Model Saved: trans_model.h5\n",
      "Model Loaded: trans_model.h5\n",
      "loss:  0.2392200529575348\n",
      "accuracy 0.904285728931427\n",
      "44/44 [==============================] - 1s 7ms/step\n",
      "[[642  58]\n",
      " [ 76 624]]\n",
      "f1-score:  0.9030390738060781\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "num_heads = 2\n",
    "ff_dim = 64\n",
    "epo_size = NO_EPO\n",
    "batch_size = 128\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "\n",
    "# Set Prompt input\n",
    "inputs_p = Input(shape=(MAX_PRO_LEN,))\n",
    "embedding_layer = EmbeddingLayer(MAX_PRO_LEN, NUM_TOKEN, embed_dim)\n",
    "x = embedding_layer(inputs_p)\n",
    "x = transformer_block(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "\n",
    "# Set txt input\n",
    "inputs_t = Input(shape=(MAX_TXT_LEN,))\n",
    "embedding_layer = EmbeddingLayer(MAX_TXT_LEN, NUM_TOKEN, embed_dim)\n",
    "y = embedding_layer(inputs_t)\n",
    "y = transformer_block(y)\n",
    "y = GlobalAveragePooling1D()(y)\n",
    "y = Dropout(0.3)(y)\n",
    "y = Dense(64, activation=\"relu\")(y)\n",
    "y = Dropout(0.3)(y)\n",
    "\n",
    "\n",
    "# Concatenate outputs from prompt and text models\n",
    "merged = Concatenate()([x, y])\n",
    "merged = Dense(units=64, activation='relu')(merged)\n",
    "merged = Dense(32, activation=\"relu\")(merged)\n",
    "outputs = Dense(units=1, activation='sigmoid')(merged)\n",
    "trans_model_2 = Model(inputs=[inputs_p, inputs_t], outputs=outputs)\n",
    "\n",
    "# Compile and train\n",
    "trans_model_2.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\n",
    "                      \"accuracy\", f1_loss])\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'trans_model.h5', monitor='val_loss', save_best_only=True)\n",
    "trans_model_2.fit([domain_1.train_prompt, domain_1.train_txt], domain_1.train_label, epochs=epo_size,\n",
    "                  batch_size=batch_size, validation_split=0.2, callbacks=[callback, model_checkpoint])\n",
    "print(\"Model Saved: trans_model.h5\")\n",
    "\n",
    "# evaluate\n",
    "trans_model_2 = tf.keras.models.load_model(\"trans_model.h5\", custom_objects={\n",
    "                                           'f1_loss': f1_loss, 'TransformerBlock': TransformerBlock, 'EmbeddingLayer': EmbeddingLayer})\n",
    "print(\"Model Loaded: trans_model.h5\")\n",
    "loss, accuracy, f1 = trans_model_2.evaluate(\n",
    "    [domain_1.test_prompt, domain_1.test_txt], domain_1.test_label, verbose=False)\n",
    "print(\"loss: \", loss)\n",
    "print(\"accuracy\", accuracy)\n",
    "trans_1_pre_rnn = trans_model_2.predict(\n",
    "    [domain_1.test_prompt, domain_1.test_txt])\n",
    "trans_1_pre_rnn = np.round(trans_1_pre_rnn).flatten()\n",
    "confusion = confusion_matrix(domain_1.test_label, trans_1_pre_rnn)\n",
    "# trans_1_pre_rnn = [0 if i.flatten()[0] > i.flatten()[1] else 1 for i in trans_1_pre_rnn]\n",
    "# confusion = confusion_matrix(domain_1.test_label, trans_1_pre_rnn)\n",
    "print(confusion)\n",
    "f1 = f1_score(domain_1.test_label, trans_1_pre_rnn)\n",
    "print(\"f1-score: \", f1)\n",
    "\n",
    "# 609/652 dropout -> 0.3 || 645/610\n",
    "# 645/610 dense 20 -> 32 || 642/624\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain 2 weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_fra = 1.6\n",
    "weight_fra = 300\n",
    "\n",
    "# _______________ Read data from domain 1 _______________\n",
    "man_1_df = pd.read_json(HUMAN_1_P)\n",
    "man_1_df[\"label\"] = HUMAN_IND\n",
    "mac_1_df = pd.read_json(MACHINE_1_P).drop(\"machine_id\", axis=1)\n",
    "mac_1_df[\"label\"] = MACHINE_IND\n",
    "domain_1_df = pd.concat([man_1_df, mac_1_df])\n",
    "\n",
    "domain_1 = DomainData(domain_1_df[[\"prompt\", \"txt\"]], domain_1_df[\"label\"])\n",
    "domain_1.t_t_spli(TEST_FRA, RANDOM_SEED)\n",
    "# domain_1.down_sampling()\n",
    "domain_1.add_padding('post', MAX_PRO_LEN, MAX_TXT_LEN)\n",
    "\n",
    "# _______________ Read data from domain 2 _______________\n",
    "man_2_df = pd.read_json(HUMAN_2_P)\n",
    "man_2_df[\"label\"] = HUMAN_IND\n",
    "mac_2_df = pd.read_json(MACHINE_2_P).drop(\"machine_id\", axis=1)\n",
    "mac_2_df[\"label\"] = MACHINE_IND\n",
    "domain_2_df = pd.concat([man_2_df, mac_2_df])\n",
    "\n",
    "domain_2 = DomainData(domain_2_df[[\"prompt\", \"txt\"]], domain_2_df[\"label\"])\n",
    "domain_2.t_t_spli(TEST_FRA, RANDOM_SEED)\n",
    "# domain_2.over_sampling(over_fra)\n",
    "domain_2.test_down()\n",
    "domain_2.add_padding('post', MAX_PRO_LEN, MAX_TXT_LEN)\n",
    "\n",
    "\n",
    "# _______________ weight data _______________\n",
    "sample_weight_1 = np.ones(len(domain_1.train_label))\n",
    "sample_weight_2 = np.ones(len(domain_2.train_label))\n",
    "sample_weight_2 *= weight_fra\n",
    "sample_weight = np.concatenate([sample_weight_1, sample_weight_2])\n",
    "\n",
    "train_prompt = np.concatenate([domain_1.train_prompt, domain_2.train_prompt])\n",
    "train_txt = np.concatenate([domain_1.train_txt, domain_2.train_txt])\n",
    "train_label = np.concatenate([domain_1.train_label, domain_2.train_label])\n",
    "\n",
    "data = list(zip(train_prompt, train_txt, train_label, sample_weight))\n",
    "random.shuffle(data)\n",
    "\n",
    "train_prompt, train_txt, train_label, sample_weight = zip(*data)\n",
    "train_prompt = np.array(train_prompt)\n",
    "train_txt = np.array(train_txt)\n",
    "train_label = np.array(train_label)\n",
    "sample_weight = np.array(sample_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "633/633 [==============================] - ETA: 0s - loss: 1.0625 - accuracy: 0.9061 - f1_loss: -0.9342WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 101s 153ms/step - loss: 1.0625 - accuracy: 0.9061 - f1_loss: -0.9342 - val_loss: 0.3983 - val_accuracy: 0.9756 - val_f1_loss: -0.9875\n",
      "Epoch 2/10\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.5160 - accuracy: 0.9672 - f1_loss: -0.9830WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 82s 129ms/step - loss: 0.5160 - accuracy: 0.9672 - f1_loss: -0.9830 - val_loss: 0.3306 - val_accuracy: 0.9711 - val_f1_loss: -0.9853\n",
      "Epoch 3/10\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.3660 - accuracy: 0.9644 - f1_loss: -0.9811WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 80s 127ms/step - loss: 0.3660 - accuracy: 0.9644 - f1_loss: -0.9811 - val_loss: 0.2696 - val_accuracy: 0.9754 - val_f1_loss: -0.9874\n",
      "Epoch 4/10\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.1431 - accuracy: 0.9784 - f1_loss: -0.9889WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 79s 125ms/step - loss: 0.1431 - accuracy: 0.9784 - f1_loss: -0.9889 - val_loss: 0.3402 - val_accuracy: 0.9784 - val_f1_loss: -0.9889\n",
      "Epoch 5/10\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.9812 - f1_loss: -0.9903WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 79s 125ms/step - loss: 0.0654 - accuracy: 0.9812 - f1_loss: -0.9903 - val_loss: 0.2962 - val_accuracy: 0.9816 - val_f1_loss: -0.9906\n",
      "Epoch 6/10\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9845 - f1_loss: -0.9920WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 80s 126ms/step - loss: 0.0492 - accuracy: 0.9845 - f1_loss: -0.9920 - val_loss: 0.3019 - val_accuracy: 0.9819 - val_f1_loss: -0.9907\n",
      "Epoch 7/10\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9873 - f1_loss: -0.9935WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 79s 125ms/step - loss: 0.0384 - accuracy: 0.9873 - f1_loss: -0.9935 - val_loss: 0.3458 - val_accuracy: 0.9832 - val_f1_loss: -0.9914\n",
      "Epoch 8/10\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9899 - f1_loss: -0.9948WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 79s 125ms/step - loss: 0.0295 - accuracy: 0.9899 - f1_loss: -0.9948 - val_loss: 0.3122 - val_accuracy: 0.9825 - val_f1_loss: -0.9910\n",
      "Epoch 9/10\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9922 - f1_loss: -0.9960WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 79s 125ms/step - loss: 0.0231 - accuracy: 0.9922 - f1_loss: -0.9960 - val_loss: 0.2390 - val_accuracy: 0.9835 - val_f1_loss: -0.9915\n",
      "Epoch 10/10\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9934 - f1_loss: -0.9966WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "633/633 [==============================] - 79s 125ms/step - loss: 0.0201 - accuracy: 0.9934 - f1_loss: -0.9966 - val_loss: 0.1698 - val_accuracy: 0.9847 - val_f1_loss: -0.9921\n",
      "Model Saved: trans_model_weighted.h5\n",
      "Model Loaded: trans_model_weighted.h5\n",
      "loss:  0.19193045794963837\n",
      "accuracy 0.925000011920929\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "[[20  0]\n",
      " [ 3 17]]\n",
      "f1-score:  0.9189189189189189\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "num_heads = 10\n",
    "ff_dim = 32\n",
    "epo_size = 10\n",
    "batch_size = 128\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "\n",
    "# Set Prompt input\n",
    "inputs_p = Input(shape=(MAX_PRO_LEN,))\n",
    "embedding_layer = EmbeddingLayer(MAX_PRO_LEN, NUM_TOKEN, embed_dim)\n",
    "x = embedding_layer(inputs_p)\n",
    "x = transformer_block(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(20, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "\n",
    "# Set txt input\n",
    "inputs_t = Input(shape=(MAX_TXT_LEN,))\n",
    "embedding_layer = EmbeddingLayer(MAX_TXT_LEN, NUM_TOKEN, embed_dim)\n",
    "y = embedding_layer(inputs_t)\n",
    "y = transformer_block(y)\n",
    "y = GlobalAveragePooling1D()(y)\n",
    "y = Dropout(0.1)(y)\n",
    "y = Dense(20, activation=\"relu\")(y)\n",
    "y = Dropout(0.1)(y)\n",
    "\n",
    "\n",
    "# Concatenate outputs from prompt and text models\n",
    "merged = Concatenate()([x, y])\n",
    "merged = Dense(units=64, activation='relu')(merged)\n",
    "merged = Dense(20, activation=\"relu\")(merged)\n",
    "outputs = Dense(units=1, activation='sigmoid')(merged)\n",
    "trans_model_2 = Model(inputs=[inputs_p, inputs_t], outputs=outputs)\n",
    "\n",
    "# Compile and train\n",
    "trans_model_2.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\n",
    "                      \"accuracy\", f1_loss])\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'trans_model_weighted.h5', monitor='val_loss', save_best_only=True)\n",
    "trans_model_2.fit([train_prompt, train_txt], train_label, epochs=epo_size, batch_size=batch_size,\n",
    "                  sample_weight=sample_weight, validation_split=0.2, callbacks=[callback, model_checkpoint])\n",
    "print(\"Model Saved: trans_model_weighted.h5\")\n",
    "\n",
    "\n",
    "## evaluate\n",
    "trans_model_2 = tf.keras.models.load_model(\"trans_model_weighted.h5\", custom_objects={\n",
    "                                           'f1_loss': f1_loss, 'TransformerBlock': TransformerBlock, 'EmbeddingLayer': EmbeddingLayer})\n",
    "print(\"Model Loaded: trans_model_weighted.h5\")\n",
    "loss, accuracy, f1 = trans_model_2.evaluate(\n",
    "    [domain_2.test_prompt, domain_2.test_txt], domain_2.test_label, verbose=False)\n",
    "print(\"loss: \", loss)\n",
    "print(\"accuracy\", accuracy)\n",
    "trans_2_pre_rnn = trans_model_2.predict(\n",
    "    [domain_2.test_prompt, domain_2.test_txt])\n",
    "trans_2_pre_rnn = np.round(trans_2_pre_rnn).flatten()\n",
    "confusion = confusion_matrix(domain_2.test_label, trans_2_pre_rnn)\n",
    "print(confusion)\n",
    "f1 = f1_score(domain_2.test_label, trans_2_pre_rnn)\n",
    "print(\"f1-score: \", f1)\n",
    "\n",
    "# 20/18 epoch: NO_EPO -> 10 ||  20/17\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 10:05:32.080838: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-26 10:05:32.081250: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-26 10:05:32.081817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-26 10:05:33.318509: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-26 10:05:33.318948: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-26 10:05:33.318966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-26 10:05:33.319373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-26 10:05:33.319419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3383 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 10:05:36.268921: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "DOMAIN_SPL = 600\n",
    "## prepare data\n",
    "test_df = pd.read_json(TEST_P)\n",
    "test_prompt = pad_sequences(\n",
    "    test_df[\"prompt\"], padding=\"post\", maxlen=MAX_PRO_LEN)\n",
    "test_txt = pad_sequences(test_df[\"txt\"], padding=\"post\", maxlen=MAX_TXT_LEN)\n",
    "\n",
    "## train model\n",
    "model_1 = tf.keras.models.load_model(\"trans_model.h5\", custom_objects={\n",
    "                                     'f1_loss': f1_loss, 'TransformerBlock': TransformerBlock, 'EmbeddingLayer': EmbeddingLayer})\n",
    "model_2 = tf.keras.models.load_model(\"trans_model_weighted.h5\", custom_objects={\n",
    "                                     'f1_loss': f1_loss, 'TransformerBlock': TransformerBlock, 'EmbeddingLayer': EmbeddingLayer})\n",
    "\n",
    "## predict\n",
    "pred = []\n",
    "pred += model_1.predict([test_prompt[:DOMAIN_SPL],\n",
    "                        test_txt[:DOMAIN_SPL]]).tolist()\n",
    "pred += model_2.predict([test_prompt[DOMAIN_SPL:],\n",
    "                        test_txt[DOMAIN_SPL:]]).tolist()\n",
    "pred = [int(i) for i in np.round(pred).flatten()]\n",
    "\n",
    "\n",
    "## save\n",
    "pred_df = pd.DataFrame(pred)\n",
    "pred_df.columns = [\"Predicted\"]\n",
    "pred_df.index.names = ['Id']\n",
    "pred_df.to_csv(\"./data/result3.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "789/789 [==============================] - 6s 7ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "result for model 1: \n",
      "confusion 1: \n",
      " [[  642    58]\n",
      " [ 2144 22373]]\n",
      "f1-score:  0.9530970435375309\n",
      "\n",
      "result for model 2: \n",
      "confusion 2: \n",
      " [[79  1]\n",
      " [ 3 17]]\n",
      "f1-score:  0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "prompt_val_1 = pd.read_csv(\"./data/test_1.csv\")[\"prompt\"].values\n",
    "prompt_val_1 = [[int(j) for j in i.split(\" \")] for i in prompt_val_1]\n",
    "txt_val_1 = pd.read_csv(\"./data/test_1.csv\")[\"txt\"].values\n",
    "txt_val_1 = [[int(j) for j in i.split(\" \")] for i in txt_val_1]\n",
    "label_val_1 = pd.read_csv(\"./data/test_1.csv\")[\"label\"].values\n",
    "\n",
    "prompt_val_2 = pd.read_csv(\"./data/test_2.csv\")[\"prompt\"].values\n",
    "prompt_val_2 = [[int(j) for j in i.split(\" \")] for i in prompt_val_2]\n",
    "txt_val_2 = pd.read_csv(\"./data/test_2.csv\")[\"txt\"].values\n",
    "txt_val_2 = [[int(j) for j in i.split(\" \")] for i in txt_val_2]\n",
    "label_val_2 = pd.read_csv(\"./data/test_2.csv\")[\"label\"].values\n",
    "\n",
    "prompt_val_1 = pad_sequences(prompt_val_1, padding=\"post\", maxlen=MAX_PRO_LEN)\n",
    "prompt_val_2 = pad_sequences(prompt_val_2, padding=\"post\", maxlen=MAX_PRO_LEN)\n",
    "txt_val_1 = pad_sequences(txt_val_1, padding=\"post\", maxlen=MAX_TXT_LEN)\n",
    "txt_val_2 = pad_sequences(txt_val_2, padding=\"post\", maxlen=MAX_TXT_LEN)\n",
    "\n",
    "model_1 = tf.keras.models.load_model(\"trans_model.h5\", custom_objects={\n",
    "                                     'f1_loss': f1_loss, 'TransformerBlock': TransformerBlock, 'EmbeddingLayer': EmbeddingLayer})\n",
    "model_2 = tf.keras.models.load_model(\"trans_model_weighted.h5\", custom_objects={\n",
    "                                     'f1_loss': f1_loss, 'TransformerBlock': TransformerBlock, 'EmbeddingLayer': EmbeddingLayer})\n",
    "\n",
    "pred_1 = model_1.predict([prompt_val_1, txt_val_1])\n",
    "pred_1 = [int(i) for i in np.round(pred_1).flatten()]\n",
    "pred_2 = model_2.predict([prompt_val_2, txt_val_2])\n",
    "pred_2 = [int(i) for i in np.round(pred_2).flatten()]\n",
    "\n",
    "print(\"result for model 1: \")\n",
    "confusion_1 = confusion_matrix(label_val_1, pred_1)\n",
    "print(\"confusion 1: \\n\", confusion_1)\n",
    "f1 = f1_score(label_val_1, pred_1)\n",
    "print(\"f1-score: \", f1)\n",
    "\n",
    "print(\"\\nresult for model 2: \")\n",
    "confusion_2 = confusion_matrix(label_val_2, pred_2)\n",
    "print(\"confusion 2: \\n\", confusion_2)\n",
    "f1_2 = f1_score(label_val_2, pred_2)\n",
    "print(\"f1-score: \", f1_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference:  331\n",
      "582\n",
      "895\n",
      "[0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 1 1\n",
      " 1 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 0 0 0 1\n",
      " 0 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 1 0\n",
      " 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 1 0 1 1 1 1 1 1\n",
      " 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1\n",
      " 1 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1\n",
      " 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 0 0 1 1 0 0 0\n",
      " 1 1 1 0 0 1 0 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1\n",
      " 0 0 0 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0\n",
      " 1 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1\n",
      " 0 1 1 1 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0\n",
      " 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1\n",
      " 1 1 1 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0]\n",
      "[2, 3, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21, 26, 28, 31, 33, 35, 36, 37, 38, 41, 46, 49, 55, 60, 62, 71, 76, 79, 83, 84, 89, 93, 97, 102, 103, 104, 105, 106, 110, 112, 113, 114, 116, 119, 121, 122, 124, 131, 132, 133, 138, 140, 141, 142, 144, 146, 148, 150, 151, 152, 153, 154, 156, 158, 162, 164, 165, 170, 173, 178, 180, 185, 186, 192, 194, 197, 201, 202, 204, 205, 210, 213, 214, 216, 217, 218, 219, 220, 221, 222, 231, 232, 235, 236, 237, 239, 242, 243, 245, 246, 247, 249, 255, 258, 259, 263, 264, 265, 266, 269, 273, 274, 275, 276, 277, 279, 280, 284, 285, 291, 292, 296, 298, 301, 303, 304, 306, 310, 311, 312, 317, 319, 320, 321, 322, 323, 324, 325, 327, 328, 329, 342, 343, 344, 345, 349, 350, 351, 352, 354, 355, 356, 359, 360, 362, 366, 368, 369, 370, 371, 372, 376, 377, 378, 380, 383, 384, 385, 386, 387, 389, 391, 392, 396, 397, 399, 402, 403, 407, 408, 409, 412, 415, 416, 421, 423, 424, 426, 429, 430, 432, 433, 435, 436, 437, 441, 442, 443, 448, 449, 450, 452, 453, 454, 455, 456, 458, 461, 462, 464, 465, 469, 470, 473, 478, 479, 481, 483, 485, 487, 490, 491, 492, 497, 500, 502, 504, 505, 512, 514, 515, 517, 519, 520, 521, 522, 523, 525, 526, 532, 536, 537, 538, 539, 541, 543, 544, 546, 550, 553, 557, 558, 559, 560, 561, 563, 564, 565, 566, 568, 569, 570, 572, 574, 575, 580, 581, 583, 584, 591, 592, 593, 594, 596, 599, 603, 606, 608, 624, 632, 641, 646, 651, 656, 668, 675, 676, 682, 684, 694, 699, 714, 716, 735, 765, 771, 777, 787, 788, 801, 804, 805, 815, 816, 820, 829, 830, 847, 854, 869, 870, 872, 875, 877, 883, 886, 896, 898, 900, 926, 934, 937, 941, 942, 967, 971, 980, 997]\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"./data/result3.csv\")\n",
    "df2 = pd.read_csv(\"./data/result3_v2.csv\")\n",
    "\n",
    "df1[\"pred_2\"] = df2[\"Predicted\"]\n",
    "df1[\"compare\"] = df1.apply(lambda x: 1 if int(x[\"pred_2\"] != x[\"Predicted\"]) else 0, axis=1)\n",
    "\n",
    "print(\"Difference: \", sum(df1[\"compare\"].values.tolist()))\n",
    "\n",
    "print(sum(df1[\"Predicted\"].to_numpy()))\n",
    "print(sum(df1[\"pred_2\"].to_numpy()))\n",
    "\n",
    "print(df1[\"compare\"].values)\n",
    "dis_m = []\n",
    "for i in range(len(df1[\"compare\"].values)):\n",
    "    if df1[\"compare\"][i] != 0:\n",
    "        dis_m.append(i)\n",
    "print(dis_m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
